{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X_train = pd.read_csv(os.path.join(os.getcwd(), \"data\", \"X_train.csv\"))\n",
    "X_test = pd.read_csv(os.path.join(os.getcwd(), \"data\", \"X_test.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(os.getcwd(), \"data\", \"y_train.csv\"))\n",
    "y_test = pd.read_csv(os.path.join(os.getcwd(), \"data\", \"y_test.csv\"))\n",
    "\n",
    "# Labelling binary features\n",
    "numerical_features = [\"age\", \"balance\", \"duration\", \"campaign\", \"pdays\", \"previous\",\"last_contact_day\"]\n",
    "categorical_features = [col for col in X_train.columns if col not in numerical_features]\n",
    "categorical_features_index = [list(X_train.columns).index(col) for col in categorical_features]\n",
    "binary_features = [\"default\",\"housing\",\"loan\"]\n",
    "not_binary_categorical = [col for col in categorical_features if col not in binary_features]\n",
    "\n",
    "le = LabelEncoder()\n",
    "for c in binary_features:\n",
    "    le.fit(X_train[c])\n",
    "    X_train[c] = le.transform(X_train[c])\n",
    "    X_test[c] = le.transform(X_test[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "smote_nc = SMOTENC(categorical_features=categorical_features_index, random_state=0, sampling_strategy=0.40)\n",
    "X_train_os, y_train_os = smote_nc.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check imbalance in taget variable\n",
    "print(y_train.value_counts() / len(y_train))\n",
    "\n",
    "print(y_train_os.value_counts() / len(y_train_os))\n",
    "\n",
    "# Check train size\n",
    "print(X_train_os.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "encoded_train = pd.DataFrame(enc.fit_transform(X_train_os[not_binary_categorical]).toarray(), columns=enc.get_feature_names_out())\n",
    "encoded_test = pd.DataFrame(enc.transform(X_test[not_binary_categorical]).toarray(), columns=enc.get_feature_names_out())\n",
    "\n",
    "X_train_enc = pd.concat([X_train_os[numerical_features],X_train_os[binary_features],encoded_train], axis=1)\n",
    "X_test_enc = pd.concat([X_test[numerical_features],X_test[binary_features], encoded_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Fit the classifier\n",
    "model.fit(X_train_enc, y_train_os.values.ravel())\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_enc)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(predictions, y_test.values.ravel())\n",
    "precision = precision_score(predictions, y_test.values.ravel())\n",
    "recall = recall_score(predictions, y_test.values.ravel())\n",
    "f1score = f1_score(predictions, y_test.values.ravel())\n",
    "\n",
    "cm = 100 * confusion_matrix(y_test.values.ravel(), predictions, labels=model.classes_) / len(y_test.values.ravel())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f} - Precision: {precision:.2f} - Recall: {recall:.2f} - F1 Score: {f1score:.2f}\")\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3 most important features and 3 less important\n",
    "importances = pd.Series(model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False)\n",
    "importances_to_plot = pd.concat([importances[:3],importances[-3:]])\n",
    "fig, ax = plt.subplots()\n",
    "importances_to_plot.plot.bar()\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6b640dea27f07f1ecf59808c3749c301dd06751a38fd49af9f594cecdfa758d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
